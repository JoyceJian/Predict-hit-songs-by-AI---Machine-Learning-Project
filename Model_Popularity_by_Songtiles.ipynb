{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "nteract": {
      "version": "0.11.2"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "“Model_Popularity_Songtile.ipynb”",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "clR-DYAm0O1e",
        "colab_type": "code",
        "outputId": "029797a9-e754-43cd-84d9-f9ebce6fee47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "\n",
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .getOrCreate()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
            "\u001b[K     |████████████████████████████████| 215.7MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 55.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.4-py2.py3-none-any.whl size=216130387 sha256=9eb7b6016adc8f21979e245e985198bd93a5f67324cb6fb1f9b103ef53718d50\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr9PnCdo0NhL",
        "colab_type": "code",
        "outputId": "e1fd00b3-f28c-4d74-f28e-6a05991a0497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Read in data from S3 Buckets\n",
        "from pyspark import SparkFiles\n",
        "url =\"https://hyd123.s3.us-east-2.amazonaws.com/songtitle_popularity.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"songtitle_popularity.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------------+\n",
            "|popularity|         song_titles|\n",
            "+----------+--------------------+\n",
            "| unpopular|        Good for You|\n",
            "| unpopular|           Body Heat|\n",
            "| unpopular|             Strings|\n",
            "| unpopular|          Aftertaste|\n",
            "| unpopular|                 Air|\n",
            "| unpopular|               Crazy|\n",
            "| unpopular|           Survivors|\n",
            "| unpopular|   A Little Too Much|\n",
            "| unpopular|           Young God|\n",
            "| unpopular|             Control|\n",
            "| unpopular|         Kid In Love|\n",
            "| unpopular|         Coming Down|\n",
            "| unpopular|              Colors|\n",
            "| unpopular|This Is What It T...|\n",
            "| unpopular|     Me & the Rhythm|\n",
            "| unpopular|          Camouflage|\n",
            "| unpopular|               Angel|\n",
            "| unpopular|      Never Be Alone|\n",
            "| unpopular|   Life of the Party|\n",
            "| unpopular|          As You Are|\n",
            "+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g2KYKe30NhT",
        "colab_type": "code",
        "outputId": "c2d506c3-34ef-4e52-987a-06d292c0ef27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature \n",
        "data_df = df.withColumn('length', length(df['song_titles']))\n",
        "data_df.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------------+------+\n",
            "|popularity|         song_titles|length|\n",
            "+----------+--------------------+------+\n",
            "| unpopular|        Good for You|    12|\n",
            "| unpopular|           Body Heat|     9|\n",
            "| unpopular|             Strings|     7|\n",
            "| unpopular|          Aftertaste|    10|\n",
            "| unpopular|                 Air|     3|\n",
            "| unpopular|               Crazy|     5|\n",
            "| unpopular|           Survivors|     9|\n",
            "| unpopular|   A Little Too Much|    17|\n",
            "| unpopular|           Young God|     9|\n",
            "| unpopular|             Control|     7|\n",
            "| unpopular|         Kid In Love|    11|\n",
            "| unpopular|         Coming Down|    11|\n",
            "| unpopular|              Colors|     6|\n",
            "| unpopular|This Is What It T...|    21|\n",
            "| unpopular|     Me & the Rhythm|    15|\n",
            "| unpopular|          Camouflage|    10|\n",
            "| unpopular|               Angel|     5|\n",
            "| unpopular|      Never Be Alone|    14|\n",
            "| unpopular|   Life of the Party|    17|\n",
            "| unpopular|          As You Are|    10|\n",
            "+----------+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGeM1ZTY0NhY",
        "colab_type": "text"
      },
      "source": [
        "### Feature Transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbcoHnVz0Nha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer\n",
        "# Create all the features to the data set\n",
        "pos_neg_to_num = StringIndexer(inputCol='popularity',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"song_titles\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"token_text\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVeNAJyf0Nhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ7v3LBD0Nht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[pos_neg_to_num, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqnoRP4L0Nh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMXC1IR10Nh9",
        "colab_type": "code",
        "outputId": "b7145556-4bfe-40e1-9ac5-a4635115773c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "# Show label and resulting features\n",
        "cleaned.select(['label', 'features']).show(truncate = False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|label|features                                                                                                                                        |\n",
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|1.0  |(262145,[16332,113432,252801,262144],[4.817589773939326,4.3067641501733345,2.466214516775848,12.0])                                             |\n",
            "|1.0  |(262145,[34121,148851,262144],[5.51073695449927,5.916202062607435,9.0])                                                                         |\n",
            "|1.0  |(262145,[182876,262144],[6.60934924316738,7.0])                                                                                                 |\n",
            "|1.0  |(262145,[51973,262144],[6.60934924316738,10.0])                                                                                                 |\n",
            "|1.0  |(262145,[188570,262144],[6.60934924316738,3.0])                                                                                                 |\n",
            "|1.0  |(262145,[176390,262144],[5.105271846391107,5.0])                                                                                                |\n",
            "|1.0  |(262145,[48310,262144],[6.60934924316738,9.0])                                                                                                  |\n",
            "|1.0  |(262145,[76764,159636,181519,227410,262144],[6.60934924316738,4.7375470662657895,5.693058511293225,3.370670791003,17.0])                        |\n",
            "|1.0  |(262145,[57304,234280,262144],[5.22305488204749,5.693058511293225,9.0])                                                                         |\n",
            "|1.0  |(262145,[14898,262144],[5.693058511293225,7.0])                                                                                                 |\n",
            "|1.0  |(262145,[132503,186480,222453,262144],[6.60934924316738,3.5648268054439574,3.776135899111164,11.0])                                             |\n",
            "|1.0  |(262145,[25217,73366,262144],[4.412124665831161,6.203884135059216,11.0])                                                                        |\n",
            "|1.0  |(262145,[61868,262144],[6.60934924316738,6.0])                                                                                                  |\n",
            "|1.0  |(262145,[15889,50134,81566,86175,108541,262144],[4.529907701487544,6.60934924316738,4.412124665831161,3.0258303047112705,4.46928307967111,21.0])|\n",
            "|1.0  |(262145,[35649,103838,113458,221047,262144],[6.60934924316738,2.759201641457322,5.51073695449927,2.8026867533970607,15.0])                      |\n",
            "|1.0  |(262145,[5173,262144],[6.60934924316738,10.0])                                                                                                  |\n",
            "|1.0  |(262145,[64554,262144],[5.51073695449927,5.0])                                                                                                  |\n",
            "|1.0  |(262145,[152959,167152,245806,262144],[5.22305488204749,4.99991133073328,4.46928307967111,14.0])                                                |\n",
            "|1.0  |(262145,[9639,33524,103838,172517,262144],[3.9012990420651703,6.203884135059216,2.759201641457322,6.203884135059216,17.0])                      |\n",
            "|1.0  |(262145,[50940,167122,252801,262144],[4.99991133073328,6.203884135059216,2.466214516775848,10.0])                                               |\n",
            "+-----+------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwTafG3G0NiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3])\n",
        "\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNX2rARH0NiN",
        "colab_type": "code",
        "outputId": "206bdede-26e5-4210-d31d-8aa33ab1834e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# Tranform the model with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------+------+-----+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|popularity|   song_titles|length|label|          token_text|stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+----------+--------------+------+-----+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|   popular|        24-Jul|     6|  0.0|            [24-jul]|   [24-jul]|(262144,[11840],[...|(262144,[11840],[...|(262145,[11840,26...|[-79.833612967563...|[0.99999999968946...|       0.0|\n",
            "|   popular|       7 Rings|     7|  0.0|          [7, rings]| [7, rings]|(262144,[77099,25...|(262144,[77099,25...|(262145,[77099,25...|[-120.01543395637...|[1.0,1.9303252602...|       0.0|\n",
            "|   popular|       7 Rings|     7|  0.0|          [7, rings]| [7, rings]|(262144,[77099,25...|(262144,[77099,25...|(262145,[77099,25...|[-120.01543395637...|[1.0,1.9303252602...|       0.0|\n",
            "|   popular|       7 Rings|     7|  0.0|          [7, rings]| [7, rings]|(262144,[77099,25...|(262144,[77099,25...|(262145,[77099,25...|[-120.01543395637...|[1.0,1.9303252602...|       0.0|\n",
            "|   popular|       7 Rings|     7|  0.0|          [7, rings]| [7, rings]|(262144,[77099,25...|(262144,[77099,25...|(262145,[77099,25...|[-120.01543395637...|[1.0,1.9303252602...|       0.0|\n",
            "|   popular|A Boy Is A Gun|    14|  0.0|[a, boy, is, a, gun]| [boy, gun]|(262144,[15889,23...|(262144,[15889,23...|(262145,[15889,23...|[-273.23155051434...|[0.99999931138883...|       0.0|\n",
            "|   popular|         A Lot|     5|  0.0|            [a, lot]|      [lot]|(262144,[128231,2...|(262144,[128231,2...|(262145,[128231,2...|[-91.201187944814...|[0.99999997864238...|       0.0|\n",
            "|   popular|         A Lot|     5|  0.0|            [a, lot]|      [lot]|(262144,[128231,2...|(262144,[128231,2...|(262145,[128231,2...|[-91.201187944814...|[0.99999997864238...|       0.0|\n",
            "|   popular|        Act Up|     6|  0.0|           [act, up]|      [act]|(262144,[179344,2...|(262144,[179344,2...|(262145,[179344,2...|[-102.22153761903...|[0.99999999999942...|       0.0|\n",
            "|   popular|     Afterglow|     9|  0.0|         [afterglow]|[afterglow]|(262144,[107320],...|(262144,[107320],...|(262145,[107320,2...|[-113.83371089329...|[0.99994266902949...|       0.0|\n",
            "+----------+--------------+------+-----+--------------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsHte53Q0NiT",
        "colab_type": "code",
        "outputId": "cc13986f-76ab-45f5-ef9d-7193a4bf0ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" % acc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.652366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2jCl1zdCpv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}